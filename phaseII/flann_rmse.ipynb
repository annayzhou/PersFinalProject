{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyflann import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import copy\n",
    "import timeit\n",
    "mydata = pd.read_csv('subset_numeric.csv')\n",
    "#mydata = pd.read_csv('subset100k.csv')\n",
    "#del mydata[\"orig_destination_distance\"]\n",
    "#dat = mydata.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.0\n"
     ]
    }
   ],
   "source": [
    "m = np.zeros((10000,100))\n",
    "m[m==0]=-1\n",
    "# Build the dataset Matrix\n",
    "# -1: no click\n",
    "# 1: click but no booking\n",
    "# >1: number of bookings\n",
    "userid = mydata['user_id'].unique()\n",
    "hotelcluster = mydata['hotel_cluster'].unique()\n",
    "for index, row in mydata.iterrows():\n",
    "    rowNum = np.where(userid==row['user_id'])\n",
    "    colNum = np.where(hotelcluster==row['hotel_cluster'])\n",
    "    if m[rowNum,colNum]==-1:\n",
    "        m[rowNum,colNum]=row['is_booking']+1\n",
    "    else:\n",
    "        m[rowNum,colNum] = m[rowNum,colNum]+row['is_booking']\n",
    "print m.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataSet(percent,m):\n",
    "    pMatrix = np.random.rand(10000,100)\n",
    "    TrainMatrix = np.zeros([10000,100])\n",
    "    TestMatrix = np.zeros([10000,100])\n",
    "    for index, x in np.ndenumerate(pMatrix):\n",
    "        if x >= percent:\n",
    "            TrainMatrix[index] = m[index]\n",
    "        else:\n",
    "            TestMatrix[index] = m[index]\n",
    "    TMatrix = copy.deepcopy(TrainMatrix)\n",
    "    TMatrix[TMatrix<0]=0\n",
    "    TTMatrix = copy.deepcopy(TestMatrix)\n",
    "    TTMatrix[TTMatrix<0]=0\n",
    "    return TrainMatrix,TestMatrix,TMatrix,TTMatrix\n",
    "\n",
    "def predict(result, rowNum, colNum, TMatrix,user_similarity):\n",
    "    topUser = result[rowNum]\n",
    "    topSimilarity = user_similarity[rowNum][topUser]\n",
    "    if topSimilarity.max()==0:\n",
    "        prediction = 0.0\n",
    "    else:\n",
    "        prediction = (TMatrix[topUser][:,colNum].T.dot(topSimilarity))/sum(topSimilarity)\n",
    "    return prediction\n",
    "\n",
    "flann = FLANN()\n",
    "def runANN(k,num_trees, TMatrix):\n",
    "    result, dists = flann.nn(TMatrix, TMatrix, num_neighbors = k, algorithm = \"kdtree\", trees = num_trees)\n",
    "    return result\n",
    "\n",
    "def runKmeans(k,num_branch,iters,TMatrix):\n",
    "    result, dists = flann.nn(TMatrix, TMatrix, num_neighbors = k, algorithm = \"kmeans\",\n",
    "                             branching = num_branch, iterations = iters)\n",
    "    return result\n",
    "\n",
    "# (l,u): range of tuning variable, l needs to be greater than 2\n",
    "def predict_all(l,u):\n",
    "    rmse = []\n",
    "    for i in range(l,u+1):\n",
    "        rmse_i = []\n",
    "        for j in range(1,6):\n",
    "            TrainMatrix,TestMatrix,TMatrix,TTMatrix = splitDataSet(0.2,m)\n",
    "            user_similarity = cosine_similarity(TMatrix)\n",
    "            result = runANN(i,20,TMatrix)\n",
    "            rMatrix = np.zeros([10000,100])\n",
    "            for index, item in np.ndenumerate(TrainMatrix):\n",
    "                if item==0:\n",
    "                    rMatrix[index] = predict(result,index[0],index[1],TMatrix,user_similarity)\n",
    "            rmseMatrix = TTMatrix-rMatrix\n",
    "            rmse_i.append(sqrt(np.square(rmseMatrix).sum() / (1.0 * np.count_nonzero(TestMatrix))))\n",
    "        print i, np.mean(rmse_i)\n",
    "        rmse.append(np.mean(rmse_i))\n",
    "    print rmse\n",
    "    return rmse\n",
    "\n",
    "def splitDataSet_2(m):\n",
    "    pMatrix = np.random.rand(10000,100)\n",
    "    Matrix_1 = np.zeros([10000,100])\n",
    "    Matrix_2 = np.zeros([10000,100])\n",
    "    Matrix_3 = np.zeros([10000,100])\n",
    "    Matrix_4 = np.zeros([10000,100])\n",
    "    Matrix_5 = np.zeros([10000,100])\n",
    "    \n",
    "    for index, x in np.ndenumerate(pMatrix):\n",
    "        if x < 0.2:\n",
    "            Matrix_1[index] = m[index]\n",
    "        elif x>=0.2 and x<0.4:\n",
    "            Matrix_2[index] = m[index]\n",
    "        elif x>=0.4 and x<0.6:\n",
    "            Matrix_3[index] = m[index]\n",
    "        elif x>=0.6 and x<0.8:\n",
    "            Matrix_4[index] = m[index]\n",
    "        elif x>=0.8:\n",
    "            Matrix_5[index] = m[index]\n",
    "    return [Matrix_1,Matrix_2,Matrix_3,Matrix_4,Matrix_5]\n",
    "\n",
    "def recommendation(k):\n",
    "    Matrix = splitDataSet_2(m)\n",
    "    resultMatrix = np.zeros([10000,100])\n",
    "    for i in range(0,5):\n",
    "        TestMatrix = copy.deepcopy(Matrix[i])\n",
    "        TrainMatrix = np.zeros([10000,100])\n",
    "        for j in range(0,5):\n",
    "            if j != i:\n",
    "                TrainMatrix += copy.deepcopy(Matrix[j])\n",
    "        TMatrix = copy.deepcopy(TrainMatrix)\n",
    "        TMatrix[TMatrix<0]=0\n",
    "        TTMatrix = copy.deepcopy(TestMatrix)\n",
    "        TTMatrix[TTMatrix<0]=0\n",
    "        user_similarity = cosine_similarity(TMatrix)\n",
    "        result = runANN(k,20,TMatrix)\n",
    "        rMatrix = np.zeros([10000,100])\n",
    "        for index, item in np.ndenumerate(TrainMatrix):\n",
    "            if item==0:\n",
    "                rMatrix[index] = predict(result,index[0],index[1],TMatrix,user_similarity)\n",
    "        resultMatrix += copy.deepcopy(rMatrix)\n",
    "    return resultMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 0.425608828925\n",
      "[0.42560882892547214]\n",
      "49.1885972023\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "predict_all(38,38)\n",
    "elapsed = timeit.default_timer()-start_time\n",
    "print elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 22 77 58 80 43 62  1 70 49]\n",
      "[77 37 80 58 43 20 62 70  1 49]\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.  29.\n",
      "  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.\n",
      "  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.  57.  58.  59.\n",
      "  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.  71.  72.  73.  74.\n",
      "  75.  76.  77.  78.  79.  80.  81.  82.  83.  84.  85.  86.  87.  88.  89.\n",
      "  90.  91.  92.  93.  94.  95.  96.  97.  98.  99.]\n",
      "100\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.  29.\n",
      "  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.\n",
      "  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.  57.  58.  59.\n",
      "  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.  71.  72.  73.  74.\n",
      "  75.  76.  77.  78.  79.  80.  81.  82.  83.  84.  85.  86.  87.  88.  89.\n",
      "  90.  91.  92.  93.  94.  95.  96.  97.  98.  99.]\n",
      "100\n",
      "4421\n"
     ]
    }
   ],
   "source": [
    "result = recommendation(38)\n",
    "\n",
    "#Popular items in the resulted matrix\n",
    "Rpopularity = np.sum(result, axis=0)\n",
    "print np.argsort(Rpopularity)[-10:,]\n",
    "\n",
    "#Popular items in the original matrix\n",
    "Rpopularity = np.sum(m, axis=0)\n",
    "print np.argsort(Rpopularity)[-10:,]\n",
    "\n",
    "#Coverage of the recommendation based on predicted results\n",
    "recommendation = np.zeros([10000,5])\n",
    "for rowNum in range(result.shape[0]):\n",
    "    recommend = np.argsort(result[rowNum])[-5:,]\n",
    "    recommendation[rowNum]=recommend\n",
    "print np.unique(recommendation)\n",
    "print len(np.unique(recommendation))\n",
    "\n",
    "#Coverage of the recomendation based on original dataset\n",
    "Mrecommendation = np.zeros([10000,5])\n",
    "for rowN in range(m.shape[0]):\n",
    "    Mrecommend = np.argsort(m[rowN])[-5:,]\n",
    "    Mrecommendation[rowN]=Mrecommend\n",
    "print np.unique(Mrecommendation)\n",
    "print len(np.unique(Mrecommendation))\n",
    "\n",
    "#Count the number of same recommendations given by our result compared to the original matrix\n",
    "count = 0\n",
    "for user in range(result.shape[0]):\n",
    "    recommend = set(np.argsort(result[user])[-5:,])\n",
    "    Mrecomend = set(np.argsort(m[user])[-5:,])\n",
    "    if (recommend.intersection(Mrecomend) != set([])):\n",
    "        count+=1\n",
    "print count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
